{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Project Description:__ <br>\n",
    "This notebook contains exploratory data analysis and the convolutional neural network model used to predict whether or not a location is susceptible to wildfires.  The data for this exploration consists of roughly 20,000 labeled satellite images. 10,000 of the images are locations which have experienced wildfires, while the other 10,000 have never seen a wildfire before.  <br>Examples below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I was unable to collect satellite imagery of the site a few days before the fire, I believe this will suffice as a proof of concept, especially since areas that experience wildfires often experience them again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plots and Graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import plotly.express as px\n",
    "import scikitplot as skplt\n",
    "import folium \n",
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "import random\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# API and Requests\n",
    "import urllib.request\n",
    "\n",
    "# Keras/Tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Shows all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Turning off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: [here](https://geo.wa.gov/datasets/wadnr::dnr-fire-statistics-2008-present-1/data?geometry=-126.579%2C45.325%2C-111.143%2C47.964&orderBy=FIRE_RGE_WHOLE_NO&orderByAsc=false&selectedAttribute=ACRES_BURNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DNR_Fire_Statistics_2008_-_Present.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True) # Shuffling the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Descriptions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Column:__\n",
    "\n",
    "- __X:__                            \n",
    "- __Y:__                              \n",
    "- __OBJECTID:__ Unique ID\n",
    "- __FIREEVENT_ID:__ Unique ID\n",
    "- __INCIDENT_NO:__ Incident Number\n",
    "- __INCIDENT_NM:__ Incident Name (trail or forest area)\n",
    "- __INCIDENT_ID:__ \n",
    "- __COUNTY_LABEL_NM:__ County Name (King, Stevens, etc. . .)          \n",
    "- __FIRE_TWP_WHOLE_NO:__ \n",
    "- __FIRE_TWP_FRACT_NO:__\n",
    "- __FIRE_RGE_WHOLE_NO:__\n",
    "- __FIRE_RGE_FRACT_NO:__\n",
    "- __FIRE_RGE_DIR_FLG:__\n",
    "- __FIRE_SECT_NO:__\n",
    "- __SITE_ELEV:__ Elevation of site\n",
    "- __FIREGCAUSE_LABEL_NM:__ Cause\n",
    "- __FIRESCAUSE_LABEL_NM:__ Secondary cause\n",
    "- __BURNESCAPE_RSN_LABEL_NM:__\n",
    "- __ACRES_BURNED:__ Acres Burned\n",
    "- __START_DT:__ Start Date\n",
    "- __START_TM:__ Start Time\n",
    "- __DSCVR_DT:__ Discovery Date\n",
    "- __DSCVR_TM:__ Discovery Time\n",
    "- __CONTROL_DT:__ Date brought under control\n",
    "- __CONTROL_TM:__ Time brought under control\n",
    "- __FIRE_OUT_DT:__ Date fire was put out\n",
    "- __FIRE_OUT_TM:__ Time fire was put out\n",
    "- __BURN_MERCH_AREA:__\n",
    "- __BURN_REPROD_AREA:__\n",
    "- __BURN_NONSTOCK_AREA:__\n",
    "- __FIREEVNT_CLASS_CD:__\n",
    "- __FIREEVNT_CLASS_LABEL_NM:__ 'Classified' or 'Other Agency'\n",
    "- __SECTION_SUBDIV_PTS_ID:__ \n",
    "- __LAT_COORD:__ Longitude\n",
    "- __LON_COORD:__ Latitude\n",
    "- __RES_ORDER_NO:__  \n",
    "- __NON_DNR_RES_ORDER_NO:__ \n",
    "- __START_OWNER_AGENCY_NM:__ Owner of land where fire started (private, government, DNR, etc. . .)\n",
    "- __START_JURISDICTION_AGENCY_NM:__ Jurisdiction where it started\n",
    "- __PROTECTION_TYPE:__ Type of Protection of area\n",
    "- __REGION_NAME:__  Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wildfire Area Image Previews:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Image examples:__<br>\n",
    "__Areas with wildfires:__\n",
    "![text](example_images/wf1.jpg)\n",
    "![text](example_images/wf2.jpg)\n",
    "![text](example_images/wf3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Wildfire Area Image Previews:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Areas without wildfires:__\n",
    "![text](example_images/nwf1.jpg)\n",
    "![text](example_images/nwf2.jpg)\n",
    "![text](example_images/nwf3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick spelling error fixed\n",
    "df['FIREGCAUSE_LABEL_NM'] = df['FIREGCAUSE_LABEL_NM'].map(lambda x: 'Misc' \n",
    "                                                          if x == 'Miscellaneou' \n",
    "                                                          else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with dates: \n",
    "df['date'] = pd.to_datetime(df.START_DT)\n",
    "df.date = df.date.dt.strftime('%m/%d/%Y')\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "# Extracting Month\n",
    "df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "df['year'] = pd.DatetimeIndex(df['date']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initial Histogram Plot\n",
    "df.hist(figsize=(15,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Chart by Region: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unique Regions:\n",
    "print('Regions of Fires:\\n\\n', df.REGION_NAME.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Chart by County:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 10 County of Fires:\\n\\n', df.COUNTY_LABEL_NM.value_counts()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elevation Histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum Elevation: ', min(df.SITE_ELEV))\n",
    "print('Maximum Elevation: ', max(df.SITE_ELEV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of elevation for wildfires\n",
    "# Most likely due to being clustered around two main sites. . . \n",
    "# I'd be interested to see where the high elevation fires are happening. . . \n",
    "# Especially the 8000 ft one!\n",
    "dftest = df[df['SITE_ELEV'] > 0]\n",
    "sns.distplot(dftest.SITE_ELEV);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map with Pins, Size by Acres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum Acres Burned: ', min(df.ACRES_BURNED))\n",
    "print('Maximum Acres Burned: ', max(df.ACRES_BURNED))\n",
    "# Change to > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Acre Histograms:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of acres burned\n",
    "# Mainly very small fires\n",
    "# Heavy skew\n",
    "dftest = df[df['ACRES_BURNED'] > 0]\n",
    "sns.distplot(dftest.ACRES_BURNED, bins = 20, kde = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of acres burned\n",
    "# Mainly very small fires\n",
    "dftest = df[df['ACRES_BURNED'] > 0]\n",
    "dftest = dftest[dftest['ACRES_BURNED'] < 100]\n",
    "sns.distplot(dftest.ACRES_BURNED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zooming in on fires under 1 acre\n",
    "dftest = df[df['ACRES_BURNED'] > 0]\n",
    "dftest = dftest[dftest['ACRES_BURNED'] < 1]\n",
    "sns.distplot(dftest.ACRES_BURNED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Maybe also try pins with small, med, and large as separate pin colors\n",
    "wa_coord = (47.4, -120.7401)\n",
    "# Creating an empty map\n",
    "map = folium.Map(location = wa_coord, zoom_start = 7.3, tiles='Cartodb Positron')\n",
    "\n",
    "# Adding markers:\n",
    "from folium.plugins import HeatMap\n",
    "HeatMap(data=df[['LAT_COORD', 'LON_COORD', 'ACRES_BURNED']].\\\n",
    "        groupby(['LAT_COORD', 'LON_COORD']).sum().reset_index().\\\n",
    "        values.tolist(), radius=11).add_to(map)\n",
    "\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df[df['ACRES_BURNED'] > 0]\n",
    "df_small = df_small[df_small['ACRES_BURNED'] < 10]\n",
    "df_med = df[df['ACRES_BURNED'] >= 10]\n",
    "df_med = df_med[df_med['ACRES_BURNED'] < 500]\n",
    "df_large = df[df['ACRES_BURNED'] >= 500]\n",
    "\n",
    "df_small = df_small[:150]\n",
    "df_med = df_med[:150]\n",
    "df_large = df_large[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wa_coord = (47.4, -120.7401)\n",
    "# Creating an empty map\n",
    "map = folium.Map(location = wa_coord, zoom_start = 7.3, tiles='Cartodb Positron')\n",
    "\n",
    "# Adding markers:\n",
    "# Small - Yellow\n",
    "for i in range(0,len(df_small)):\n",
    "    folium.CircleMarker([df_small.iloc[i]['LAT_COORD'], \n",
    "                         df_small.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'yellow',\n",
    "                         fill_color='white',\n",
    "                         popup=df_small.iloc[i]['ACRES_BURNED']).add_to(map)\n",
    "    \n",
    "# Med - Orange    \n",
    "for i in range(0,len(df_med)):\n",
    "    folium.CircleMarker([df_med.iloc[i]['LAT_COORD'], \n",
    "                         df_med.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'orange',\n",
    "                         fill_color='white',\n",
    "                         popup=df_med.iloc[i]['ACRES_BURNED']).add_to(map)\n",
    "# Large - Red    \n",
    "for i in range(0,len(df_large)):\n",
    "    folium.CircleMarker([df_large.iloc[i]['LAT_COORD'], \n",
    "                         df_large.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'red',\n",
    "                         fill_color='white',\n",
    "                         popup=df_large.iloc[i]['ACRES_BURNED']).add_to(map)\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map with Pins, Color by Date: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Earliest Start Date: ', min(df.START_DT))\n",
    "print('Latest Start Date: ', max(df.START_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most fires happening in July/Aug - no surprise\n",
    "df.month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jul = df[df['month'] == 7]\n",
    "df_aug = df[df['month'] == 8]\n",
    "df_sept = df[df['month'] ==  9]\n",
    "#df_other = df[df['month'] ==  [7,8,9]]\n",
    "# Limiting Sample\n",
    "df_jul = df_jul[:150]\n",
    "df_aug = df_aug[:150]\n",
    "df_sept = df_sept[:150]\n",
    "#df_other = df_other[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_coord = (47.4, -120.7401)\n",
    "# Creating an empty map\n",
    "map = folium.Map(location = wa_coord, zoom_start = 7.3, tiles='Cartodb Positron')\n",
    "\n",
    "# df_jul\n",
    "# df_aug\n",
    "# df_sept\n",
    "# Adding markers:\n",
    "# July - Yellow\n",
    "for i in range(0,len(df_jul)):\n",
    "    folium.CircleMarker([df_jul.iloc[i]['LAT_COORD'], \n",
    "                         df_jul.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'yellow',\n",
    "                         fill_color='white',\n",
    "                         popup=df_jul.iloc[i]['month']).add_to(map)\n",
    "    \n",
    "# Aug - Orange    \n",
    "for i in range(0,len(df_aug)):\n",
    "    folium.CircleMarker([df_aug.iloc[i]['LAT_COORD'], \n",
    "                         df_aug.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'orange',\n",
    "                         fill_color='white',\n",
    "                         popup=df_aug.iloc[i]['month']).add_to(map)\n",
    "# Sept - Red    \n",
    "for i in range(0,len(df_sept)):\n",
    "    folium.CircleMarker([df_sept.iloc[i]['LAT_COORD'], \n",
    "                         df_sept.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'red',\n",
    "                         fill_color='white',\n",
    "                         popup=df_sept.iloc[i]['month']).add_to(map)\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map with Pins, Color by Cause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cause of Fires:\\n\\n',df.FIREGCAUSE_LABEL_NM.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lightning = df[df['FIREGCAUSE_LABEL_NM'] == 'Lightning']\n",
    "df_arson = df[df['FIREGCAUSE_LABEL_NM'] == 'Arson']\n",
    "df_debris = df[df['FIREGCAUSE_LABEL_NM'] == 'Debris Burn']\n",
    "# Limiting Sample\n",
    "df_lightning = df_lightning[:150]\n",
    "df_arson = df_arson[:150]\n",
    "df_debris = df_debris[:150]\n",
    "###\n",
    "df100 = df[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Folium with Markers\n",
    "# Idea: Change to arson vs not arson\n",
    "# add legend\n",
    "# Shuffle data!!\n",
    "# Add Lightnight\n",
    "\n",
    "\n",
    "wa_coord = (47.4, -120.7401)\n",
    "# Creating an empty map\n",
    "map = folium.Map(location = wa_coord, zoom_start = 7.3, tiles='Cartodb Positron')\n",
    "\n",
    "# Lightning - Yellow\n",
    "for i in range(0,len(df_lightning)):\n",
    "    folium.CircleMarker([df_lightning.iloc[i]['LAT_COORD'], \n",
    "                         df_lightning.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'yellow',\n",
    "                         fill_color='white',\n",
    "                         popup=df_lightning.iloc[i]['FIREGCAUSE_LABEL_NM']).add_to(map)\n",
    "    \n",
    "# Arson - Red    \n",
    "for i in range(0,len(df_arson)):\n",
    "    folium.CircleMarker([df_arson.iloc[i]['LAT_COORD'], \n",
    "                         df_arson.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'red',\n",
    "                         fill_color='white',\n",
    "                         popup=df_arson.iloc[i]['FIREGCAUSE_LABEL_NM']).add_to(map)\n",
    "# Debris - Blue    \n",
    "for i in range(0,len(df_debris)):\n",
    "    folium.CircleMarker([df_debris.iloc[i]['LAT_COORD'], \n",
    "                         df_debris.iloc[i]['LON_COORD']],\n",
    "                         radius = 3,\n",
    "                         color= 'blue',\n",
    "                         fill_color='white',\n",
    "                         popup=df_debris.iloc[i]['FIREGCAUSE_LABEL_NM']).add_to(map)\n",
    "\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map with Pins, Color by Length of Time of Fire:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animated Map Over Time by Year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use group by over year with sum of acres burned and total number of fires\n",
    "# Use stacked line plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animated Map Over Time by Month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i.e. everything flattened to one year. . . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there are patterns by size, location, cause, etc. . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER TO SHUFFLE IMAGES\n",
    "# Paths:\n",
    "# /Users/Thomas/Desktop/capstone/images/test_wf\n",
    "# /Users/Thomas/Desktop/capstone/images/test_nwf\n",
    "# Images should be 350x350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('WF')\n",
    "\n",
    "for dirname, _, filenames in os.walk('/Users/Thomas/Desktop/capstone/images/test_wf'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "print ('\\nNWF')\n",
    "        \n",
    "for dirname, _, filenames in os.walk('/Users/Thomas/Desktop/capstone/images/test_nwf'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '/Users/Thomas/Desktop/capstone/images/test_wf/45.93476,-121.498236.jpg'\n",
    "image = Image.open(x)\n",
    "print(image.format)\n",
    "print(image.mode)\n",
    "print(image.size)\n",
    "# show the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ZONE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths:\n",
    "# Train - 15 each\n",
    "train_folder = '/Users/Thomas/Desktop/split/train'\n",
    "train_wf = '/Users/Thomas/Desktop/split/train/wf'\n",
    "train_nwf = '/Users/Thomas/Desktop/split/train/nwf'\n",
    "\n",
    "# Test - 5 each\n",
    "test_folder = '/Users/Thomas/Desktop/split/test'\n",
    "test_wf = '/Users/Thomas/Desktop/split/test/wf'\n",
    "test_nwf = '/Users/Thomas/Desktop/split/test/nwf'\n",
    "\n",
    "# Val - 5 each\n",
    "val_folder = '/Users/Thomas/Desktop/split/val'\n",
    "val_wf = '/Users/Thomas/Desktop/split/val/wf'\n",
    "val_nwf = '/Users/Thomas/Desktop/split/val/nwf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_wf = [file for file in os.listdir(val_wf) if file.endswith('.jpg')]\n",
    "imgs_wf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ASSISTANCE HERE - MAKE SURE THIS WORKS \n",
    "# This is turning them into 64x64x3 images\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(64, 64), batch_size = 2000)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(64, 64), batch_size = 200) \n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(64, 64), batch_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to 1d array:\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lablels for the images:\n",
    "train_y = np.reshape(train_labels[:,0], (2000,1))\n",
    "test_y = np.reshape(test_labels[:,0], (200,1))\n",
    "val_y = np.reshape(val_labels[:,0], (200,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(12288,))) # 2 hidden layers\n",
    "model.add(layers.Dense(7, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histoire = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=10,\n",
    "                    validation_data=(val_images, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END TEST ZONE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Precision:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Deployment Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input lon\n",
    "# input lat\n",
    "# api call for url\n",
    "# run image through neural net\n",
    "# display image and result, perhaps as a percentage. . . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pic of the whole thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
